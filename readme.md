# MARL Resource Allocation - Master Thesis

Dit is de repository voor mijn master thesis project. In dit project ontwikkel ik een Multi-Agent Reinforcement Learning (MARL) oplossing voor resource allocation in business processen.

## ğŸ¯ Concept

Het systeem modelleert elke resource uit event logs als een autonome agent. Deze agents "volunteeren" of ze een inkomende taak willen aannemen op basis van geleerde strategieÃ«n. Het doel is om de totale doorlooptijd van cases te optimaliseren.

## ğŸ“ Repository Structuur

```
master-cope/
â”‚
â”œâ”€â”€ src/                           # Broncode modules
â”‚   â”œâ”€â”€ core/                      # Kern configuratie en utilities
â”‚   â”‚   â”œâ”€â”€ config.py             # Dataset configuratie (kolom mapping)
â”‚   â”‚   â”œâ”€â”€ env_config.py         # Environment parameters
â”‚   â”‚   â””â”€â”€ display.py            # Terminal output helpers
â”‚   â”‚
â”‚   â”œâ”€â”€ environment/               # Custom MARL omgeving
â”‚   â”‚   â”œâ”€â”€ custom_environment.py # PettingZoo environment implementatie
â”‚   â”‚   â”œâ”€â”€ objects.py            # Agent, Task, Case objecten
â”‚   â”‚   â”œâ”€â”€ duration_distribution.py  # Task duration modeling
â”‚   â”‚   â”œâ”€â”€ reward.py             # Reward functie voor agents
â”‚   â”‚   â”œâ”€â”€ data_handling.py      # Event log verwerking
â”‚   â”‚   â””â”€â”€ typed_queue.py        # Queue implementatie
â”‚   â”‚
â”‚   â”œâ”€â”€ algorithms/                # RL algoritmes
â”‚   â”‚   â”œâ”€â”€ mappo/                # Multi-Agent PPO
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py          # MAPPO agent (actor-critic)
â”‚   â”‚   â”‚   â”œâ”€â”€ trainer.py        # Training loop
â”‚   â”‚   â”‚   â”œâ”€â”€ online_trainer.py # Online training variant
â”‚   â”‚   â”‚   â””â”€â”€ networks.py       # Neural network architectures
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ qmix/                 # QMIX algoritme
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py          # QMIX agent met mixing network
â”‚   â”‚   â”‚   â””â”€â”€ trainer.py        # QMIX training loop
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ baselines/            # Baseline agents voor vergelijking
â”‚   â”‚       â””â”€â”€ baselines.py      # Random, BestMedian, GroundTruth
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/             # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ load_data.py          # Event log laden en splitten
â”‚   â”‚   â””â”€â”€ preprocessing.py      # Data cleaning
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utilities
â”‚       â””â”€â”€ duration_fitting.py   # Duration distribution fitting
â”‚
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â”œâ”€â”€ 1_prepare_data.py         # ğŸ“¦ Fase 1 - Data preprocessing
â”‚   â”œâ”€â”€ 2_fit_distributions.py    # ğŸ“Š Fase 2 - Distribution fitting
â”‚   â”œâ”€â”€ 3_train.py                # ğŸš€ Fase 3 - Model training
â”‚   â”œâ”€â”€ 4_evaluate.py             # ğŸ“ˆ Fase 4 - Model evaluation
â”‚   â”œâ”€â”€ 5_compare_models.py       # ğŸ” Fase 5 - Model comparison
â”‚   â”œâ”€â”€ hyperparameter_search.py  # ğŸ”¬ Geautomatiseerde hyperparameter search
â”‚   â”œâ”€â”€ train.py                  # ğŸš€ Legacy - Single script training
â”‚   â”œâ”€â”€ evaluate/                 # Evaluatie scripts
â”‚   â””â”€â”€ demo/                     # Demo scripts
â”‚
â”œâ”€â”€ configs/                       # YAML configuratie bestanden
â”‚   â”œâ”€â”€ default.yaml              # Default hyperparameters
â”‚   â””â”€â”€ experiments/              # Experiment-specifieke configs
â”‚       â”œâ”€â”€ small_network.yaml    # Klein netwerk configuratie
â”‚       â”œâ”€â”€ large_network.yaml    # Groot netwerk configuratie
â”‚       â””â”€â”€ high_lr.yaml          # Hoge learning rate config
â”‚
â”œâ”€â”€ analysis/                      # Analyse en visualisatie
â”‚   â”œâ”€â”€ notebooks/                # Jupyter notebooks voor analyse
â”‚   â”œâ”€â”€ plotting/                 # Plot scripts
â”‚   â””â”€â”€ metrics/                  # Metric berekeningen
â”‚
â”œâ”€â”€ data/                          # Data folders
â”‚   â”œâ”€â”€ input/                    # Event logs (CSV bestanden)
â”‚   â”œâ”€â”€ processed/                # Preprocessed data
â”‚   â””â”€â”€ distributions/            # Fitted duration distributions
â”‚
â”œâ”€â”€ experiments/                   # Training runs en resultaten
â”œâ”€â”€ tests/                         # Unit tests
â”œâ”€â”€ docs/                          # Documentatie bestanden
â””â”€â”€ requirements.txt              # Python dependencies

```

## ğŸš€ Gebruik

### Optie 1: Modular Pipeline (Aanbevolen voor Hyperparameter Tuning)

De modular pipeline splitst training op in herbruikbare fasen, ideaal voor hyperparameter optimization:

#### **Fase 1: Data Preprocessing** (eenmalig per dataset)
```bash
python scripts/1_prepare_data.py \
  --input data/input/jouw_eventlog.csv \
  --output data/processed/preprocessed_data.pkl
```
- Laadt event log
- Verwijdert korte cases
- Splitst in train/test sets (83/17)
- Slaat op als pickle bestand

#### **Fase 2: Distribution Fitting** (eenmalig per dataset)
```bash
python scripts/2_fit_distributions.py \
  --data data/processed/preprocessed_data.pkl \
  --output data/distributions/fitted_distributions.pkl
```
- Fit duration distributions op training data
- Slaat gefitte distributies op voor hergebruik

#### **Fase 3: Training** (run meerdere keren met verschillende configs)
```bash
# Met default configuratie
python scripts/3_train.py \
  --data data/processed/preprocessed_data.pkl \
  --distributions data/distributions/fitted_distributions.pkl

# Met custom config
python scripts/3_train.py \
  --data data/processed/preprocessed_data.pkl \
  --distributions data/distributions/fitted_distributions.pkl \
  --config configs/experiments/large_network.yaml \
  --name "large_network_exp"
```
- Traint model met YAML configuratie
- Slaat model op in `experiments/`

#### **Fase 4: Evaluation**
```bash
python scripts/4_evaluate.py \
  --model experiments/exp_20231215_120000/models \
  --data data/processed/preprocessed_data.pkl \
  --distributions data/distributions/fitted_distributions.pkl \
  --episodes 20
```
- Evalueert trained model op test data
- Genereert evaluation metrics en resultaten

#### **Fase 5: Model Comparison**
```bash
python scripts/5_compare_models.py \
  --models experiments/exp1/models experiments/exp2/models experiments/exp3/models \
  --data data/processed/preprocessed_data.pkl \
  --distributions data/distributions/fitted_distributions.pkl \
  --episodes 20
```
- Vergelijkt meerdere models side-by-side
- Genereert comparison table en relatieve performance

#### **Hyperparameter Search**
```bash
# Grid search met default parameters
python scripts/hyperparameter_search.py \
  --data data/processed/preprocessed_data.pkl \
  --distributions data/distributions/fitted_distributions.pkl \
  --search-type grid

# Random search met custom parameters
python scripts/hyperparameter_search.py \
  --data data/processed/preprocessed_data.pkl \
  --distributions data/distributions/fitted_distributions.pkl \
  --search-type random \
  --param-config configs/param_search.json \
  --n-trials 20
```
- Automatiseert hyperparameter optimization
- Traint meerdere models met verschillende configuraties
- Vergelijkt automatisch alle resultaten

### Optie 2: Single-Script Training (Legacy)

Voor snelle single runs:

```bash
# Zet je event log in data/input/
# Pas src/core/config.py aan voor je dataset kolommen
python scripts/train.py
```

### Configuratie

#### **YAML Config Bestanden** (`configs/`)
- `configs/default.yaml`: Default hyperparameters
- `configs/experiments/small_network.yaml`: Kleiner netwerk (sneller)
- `configs/experiments/large_network.yaml`: Groter netwerk (meer capaciteit)
- `configs/experiments/high_lr.yaml`: Hogere learning rate

Config structuur:
```yaml
training:
  episodes: 100
  policy_update_epochs: 10

network:
  actor_hidden_size: 128
  critic_hidden_size: 256
  dropout_rate: 0.2
  weight_init: "xavier_uniform"

learning:
  lr_actor: 0.0003
  lr_critic: 0.0003
  gamma: 0.99

ppo:
  clip_param: 0.2
  batch_size: 32768
```

#### **Event Log Configuratie** (`src/core/config.py`):
- Definieer kolom mappings voor je dataset
- Specificeer case ID, activity, resource, timestamp kolommen

#### **Environment Parameters** (`src/core/env_config.py`):
- Debug settings
- Simulatie parameters

## ğŸ§  Algoritmes

### MAPPO (Multi-Agent Proximal Policy Optimization)
- Gebruikt in `src/algorithms/mappo/`
- Actor-critic architectuur
- Geschikt voor cooperative multi-agent settings

### QMIX
- Gebruikt in `src/algorithms/qmix/`
- Value-based methode met mixing network
- Combineert individuele agent Q-values

### Baselines
- **Random**: Selecteert acties random
- **BestMedian**: Alleen best presterende agent volunteert
- **GroundTruth**: Volgt werkelijke assignments uit data

## ğŸ“Š Evaluatie & Analyse

- **Evaluation scripts**: `scripts/evaluate/`
- **Plotting tools**: `analysis/plotting/`
- **Jupyter notebooks**: `analysis/notebooks/`
- **Resultaten**: Worden opgeslagen in `experiments/`

## ğŸ”§ Dependencies

```bash
pip install -r requirements.txt
```

Belangrijkste dependencies:
- PyTorch (deep learning)
- PettingZoo (multi-agent environments)
- Pandas (data processing)
- NumPy, Matplotlib, etc.

## ğŸ“– Environment Details

De environment is gebouwd met de **PettingZoo** library en is gebaseerd op het [AgentSimulator](https://github.com/lukaskirchdorfer/AgentSimulator) paper.

### Key Components:

1. **Agents (Resources)**: Elke resource wordt een zelfstandige agent
2. **Tasks**: Individuele activiteiten uit de event log
3. **Cases**: Complete process instances
4. **Observation Space**: Agent ziet eigen staat + beschikbare tasks
5. **Action Space**: Binary (volunteer voor task of niet)
6. **Reward**: Gebaseerd op case completion time vs historische performance

## ğŸ“ Workflow

### Modular Pipeline Workflow (Aanbevolen)

```
1_prepare_data.py         â†’ data/processed/preprocessed_data.pkl
         â†“
2_fit_distributions.py    â†’ data/distributions/fitted_distributions.pkl
         â†“
3_train.py (meerdere runs met verschillende configs)
         â†“                â†“                â†“
    model_1/         model_2/         model_3/
         â†“                â†“                â†“
4_evaluate.py        4_evaluate.py    4_evaluate.py
         â†“                â†“                â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                5_compare_models.py
                         â†“
            ğŸ“Š Best model selectie
```

### Stappen:

1. **Data Preprocessing** (1x per dataset) â†’ Event logs preprocessen en splitsen
2. **Distribution Fitting** (1x per dataset) â†’ Task duration distributions fitten
3. **Training** (Nx per experiment) â†’ Meerdere models trainen met verschillende configs
4. **Evaluation** â†’ Individuele model performance evalueren
5. **Comparison** â†’ Alle models vergelijken en beste selecteren
6. **Analyse** â†’ Resultaten visualiseren en interpreteren

**Voordeel**: Fase 1 en 2 hoeven maar 1x uitgevoerd te worden. Fase 3 kan parallel voor meerdere hyperparameter configuraties, wat hyperparameter tuning veel efficiÃ«nter maakt.

## ğŸ“ Master Thesis Context

Dit project onderzoekt hoe MARL gebruikt kan worden voor resource allocation optimalisatie in business processen, met focus op:
- Autonome agent decision making
- Cooperative behavior learning
- Process optimization without explicit rules
- Comparison with traditional allocation strategies
