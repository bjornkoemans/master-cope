# MARL Resource Allocation - Master Thesis

Dit is de repository voor mijn master thesis project. In dit project ontwikkel ik een Multi-Agent Reinforcement Learning (MARL) oplossing voor resource allocation in business processen.

## ğŸ¯ Concept

Het systeem modelleert elke resource uit event logs als een autonome agent. Deze agents "volunteeren" of ze een inkomende taak willen aannemen op basis van geleerde strategieÃ«n. Het doel is om de totale doorlooptijd van cases te optimaliseren.

## ğŸ“ Repository Structuur

```
master-cope/
â”‚
â”œâ”€â”€ src/                           # Broncode modules
â”‚   â”œâ”€â”€ core/                      # Kern configuratie en utilities
â”‚   â”‚   â”œâ”€â”€ config.py             # Dataset configuratie (kolom mapping)
â”‚   â”‚   â”œâ”€â”€ env_config.py         # Environment parameters
â”‚   â”‚   â””â”€â”€ display.py            # Terminal output helpers
â”‚   â”‚
â”‚   â”œâ”€â”€ environment/               # Custom MARL omgeving
â”‚   â”‚   â”œâ”€â”€ custom_environment.py # PettingZoo environment implementatie
â”‚   â”‚   â”œâ”€â”€ objects.py            # Agent, Task, Case objecten
â”‚   â”‚   â”œâ”€â”€ duration_distribution.py  # Task duration modeling
â”‚   â”‚   â”œâ”€â”€ reward.py             # Reward functie voor agents
â”‚   â”‚   â”œâ”€â”€ data_handling.py      # Event log verwerking
â”‚   â”‚   â””â”€â”€ typed_queue.py        # Queue implementatie
â”‚   â”‚
â”‚   â”œâ”€â”€ algorithms/                # RL algoritmes
â”‚   â”‚   â”œâ”€â”€ mappo/                # Multi-Agent PPO
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py          # MAPPO agent (actor-critic)
â”‚   â”‚   â”‚   â”œâ”€â”€ trainer.py        # Training loop
â”‚   â”‚   â”‚   â”œâ”€â”€ online_trainer.py # Online training variant
â”‚   â”‚   â”‚   â””â”€â”€ networks.py       # Neural network architectures
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ qmix/                 # QMIX algoritme
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py          # QMIX agent met mixing network
â”‚   â”‚   â”‚   â””â”€â”€ trainer.py        # QMIX training loop
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ baselines/            # Baseline agents voor vergelijking
â”‚   â”‚       â””â”€â”€ baselines.py      # Random, BestMedian, GroundTruth
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/             # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ load_data.py          # Event log laden en splitten
â”‚   â”‚   â””â”€â”€ preprocessing.py      # Data cleaning
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utilities
â”‚       â””â”€â”€ duration_fitting.py   # Duration distribution fitting
â”‚
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â”œâ”€â”€ train.py                  # ğŸš€ HOOFDSCRIPT - Training en evaluatie
â”‚   â”œâ”€â”€ evaluate/                 # Evaluatie scripts
â”‚   â””â”€â”€ demo/                     # Demo scripts
â”‚
â”œâ”€â”€ analysis/                      # Analyse en visualisatie
â”‚   â”œâ”€â”€ notebooks/                # Jupyter notebooks voor analyse
â”‚   â”œâ”€â”€ plotting/                 # Plot scripts
â”‚   â””â”€â”€ metrics/                  # Metric berekeningen
â”‚
â”œâ”€â”€ data/                          # Data folders
â”‚   â”œâ”€â”€ input/                    # Event logs (CSV bestanden)
â”‚   â”œâ”€â”€ processed/                # Preprocessed data
â”‚   â””â”€â”€ distributions/            # Fitted duration distributions
â”‚
â”œâ”€â”€ experiments/                   # Training runs en resultaten
â”œâ”€â”€ tests/                         # Unit tests
â”œâ”€â”€ docs/                          # Documentatie bestanden
â””â”€â”€ requirements.txt              # Python dependencies

```

## ğŸš€ Gebruik

### 1. Training Run

Om het systeem te trainen op je event logs:

```bash
# Zet je event log in data/input/
# Pas src/core/config.py aan voor je dataset kolommen
python scripts/train.py
```

### 2. Configuratie

**Event Log Configuratie** (`src/core/config.py`):
- Definieer kolom mappings voor je dataset
- Specificeer case ID, activity, resource, timestamp kolommen

**Environment Parameters** (`src/core/env_config.py`):
- Debug settings
- Simulatie parameters

### 3. Preprocessing

Data preprocessing stappen:
1. Event logs laden vanuit `data/input/`
2. Korte cases verwijderen (< 3 stappen)
3. Train/test split
4. Duration distributions fitten

## ğŸ§  Algoritmes

### MAPPO (Multi-Agent Proximal Policy Optimization)
- Gebruikt in `src/algorithms/mappo/`
- Actor-critic architectuur
- Geschikt voor cooperative multi-agent settings

### QMIX
- Gebruikt in `src/algorithms/qmix/`
- Value-based methode met mixing network
- Combineert individuele agent Q-values

### Baselines
- **Random**: Selecteert acties random
- **BestMedian**: Alleen best presterende agent volunteert
- **GroundTruth**: Volgt werkelijke assignments uit data

## ğŸ“Š Evaluatie & Analyse

- **Evaluation scripts**: `scripts/evaluate/`
- **Plotting tools**: `analysis/plotting/`
- **Jupyter notebooks**: `analysis/notebooks/`
- **Resultaten**: Worden opgeslagen in `experiments/`

## ğŸ”§ Dependencies

```bash
pip install -r requirements.txt
```

Belangrijkste dependencies:
- PyTorch (deep learning)
- PettingZoo (multi-agent environments)
- Pandas (data processing)
- NumPy, Matplotlib, etc.

## ğŸ“– Environment Details

De environment is gebouwd met de **PettingZoo** library en is gebaseerd op het [AgentSimulator](https://github.com/lukaskirchdorfer/AgentSimulator) paper.

### Key Components:

1. **Agents (Resources)**: Elke resource wordt een zelfstandige agent
2. **Tasks**: Individuele activiteiten uit de event log
3. **Cases**: Complete process instances
4. **Observation Space**: Agent ziet eigen staat + beschikbare tasks
5. **Action Space**: Binary (volunteer voor task of niet)
6. **Reward**: Gebaseerd op case completion time vs historische performance

## ğŸ“ Workflow

1. **Data Laden** â†’ Event logs uit `data/input/`
2. **Preprocessing** â†’ Cleaning, filtering, train/test split
3. **Distribution Fitting** â†’ Task duration distributions fitten
4. **Training** â†’ MAPPO/QMIX agent training
5. **Evaluation** â†’ Performance vergelijking met baselines
6. **Analyse** â†’ Resultaten visualiseren en interpreteren

## ğŸ“ Master Thesis Context

Dit project onderzoekt hoe MARL gebruikt kan worden voor resource allocation optimalisatie in business processen, met focus op:
- Autonome agent decision making
- Cooperative behavior learning
- Process optimization without explicit rules
- Comparison with traditional allocation strategies
